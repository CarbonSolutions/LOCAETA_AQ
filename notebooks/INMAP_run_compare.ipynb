{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare TWO INMAP simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import os\n",
    "\n",
    "def load_shapefile(shapefile_path):\n",
    "    gdf = gpd.read_file(shapefile_path)\n",
    "    if gdf.crs is None or gdf.crs.is_geographic:\n",
    "        gdf = gdf.set_crs('EPSG:4269', allow_override=True)\n",
    "    return gdf\n",
    "\n",
    "def plot_difference_map(gdf1, gdf2, field, output_dir, year):\n",
    "    # Ensure both GeoDataFrames have the same CRS\n",
    "    if gdf1.crs != gdf2.crs:\n",
    "        gdf2 = gdf2.to_crs(gdf1.crs)\n",
    "\n",
    "    # Calculate the difference between the two shapefiles\n",
    "    gdf1 = gdf1.rename(columns={field: f'{field}_1'})\n",
    "    gdf2 = gdf2.rename(columns={field: f'{field}_2'})\n",
    "    joined_gdf = gpd.sjoin(gdf1, gdf2, how=\"inner\", op='intersects')\n",
    "    joined_gdf['difference'] = joined_gdf[f'{field}_1'] - joined_gdf[f'{field}_2']\n",
    "\n",
    "    # Define a color map for the difference\n",
    "    color_map = mcolors.LinearSegmentedColormap.from_list(\n",
    "        'custom_colormap',\n",
    "        ['blue', 'white', 'red']\n",
    "    )\n",
    "\n",
    "    # Normalize the color map to the range of values you want to display\n",
    "    norm = mcolors.BoundaryNorm([-50, -20, -10, -5, -1, 1, 5, 10, 20, 50], color_map.N)\n",
    "\n",
    "    # Create a plot\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(15, 10), subplot_kw={'projection': ccrs.LambertConformal()})\n",
    "\n",
    "    # Plot polygons without the grid lines\n",
    "    gdf1.plot(ax=ax, facecolor='none', edgecolor='gray', linewidth=0.5, transform=ccrs.PlateCarree())\n",
    "\n",
    "\n",
    "    # Plot the differences as filled polygons\n",
    "    joined_gdf.plot(column='difference', cmap=color_map, linewidth=0.0, ax=ax, edgecolor='none', norm=norm, legend=False, transform=ccrs.PlateCarree(), alpha=0.9)\n",
    "\n",
    "    # Add state and county borders for reference\n",
    "    ax.add_feature(cfeature.COASTLINE)\n",
    "    ax.add_feature(cfeature.BORDERS, linestyle=':')\n",
    "    ax.add_feature(cfeature.STATES, linestyle=':', edgecolor='gray')\n",
    "\n",
    "    # Color bar\n",
    "    sm = plt.cm.ScalarMappable(cmap=color_map, norm=norm)\n",
    "    sm._A = []\n",
    "    cbar = fig.colorbar(sm, ax=ax, orientation='horizontal', pad=0.05, aspect=50)\n",
    "    cbar.set_label('Difference in PM2.5 Concentration')\n",
    "\n",
    "    # Titles and labels\n",
    "    ax.set_title(f'Difference in PM2.5 Concentration between Two Runs ({year})', fontsize=16)\n",
    "\n",
    "    # Set the extent to cover the CONUS region\n",
    "    ax.set_extent([-125, -66.5, 24, 50], crs=ccrs.PlateCarree())\n",
    "\n",
    "    # Save the plot to a file\n",
    "    plt.savefig(os.path.join(output_dir, f'difference_pm25_map_{year}.png'), dpi=300, bbox_inches='tight')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "inmap_run_dir = '/Users/yunhalee/Documents/LOCAETA/RCM/INMAP/inmap-1.9.6-gridsplit/outputs/'\n",
    "analysis_output_dir = '/Users/yunhalee/Documents/LOCAETA/LOCAETA_AQ/outputs/model_analysis/'\n",
    "webdata_path = '/Users/yunhalee/Documents/LOCAETA/github/LOCAETA/WebTool/Data/'\n",
    "\n",
    "# Define pairs of base and sensitivity runs\n",
    "run_pairs = {\n",
    "    #  'CO_CCS': {\n",
    "    #      'base': 'base_nei2020/2020nei_output_run_steady.shp',\n",
    "    #      'sens': 'CO_CCS/2020nei_output_run_steady.shp'\n",
    "    #  },\n",
    "    # 'CO_CCS_wo_NH3_VOC': {\n",
    "    #     'base': 'base_nei2020/2020nei_output_run_steady.shp',\n",
    "    #     'sens': 'CO_CCS_wo_NH3_VOC/2020nei_output_run_steady.shp'\n",
    "    # },\n",
    "    # 'CO_Suncor_wo_NH3_VOC': {\n",
    "    #     'base': 'base_nei2020/2020nei_output_run_steady.shp',\n",
    "    #     'sens': 'CO_Suncor_CCS_wo_NH3_VOC/2020nei_output_run_steady.shp'\n",
    "    # }\n",
    "    # 'NEI_no_Landfill_2001411':{\n",
    "    #     'base': 'base_nei2020/2020nei_output_run_steady.shp',\n",
    "    #     'sens': 'NEI_no_Landfill_2001411/2020nei_output_run_steady.shp'\n",
    "    # }\n",
    "    'TN_DataCenter_NOx_2ppm': {\n",
    "        'base': 'base_nei2020/2020nei_output_run_steady.shp',\n",
    "        'sens': 'data_center_NOx_2ppm/2020nei_output_run_steady.shp'\n",
    "    },\n",
    "    'TN_DataCenter_NOx_25ppm': {\n",
    "        'base': 'base_nei2020/2020nei_output_run_steady.shp',\n",
    "        'sens': 'data_center_NOx_25ppm/2020nei_output_run_steady.shp'\n",
    "    }\n",
    "\n",
    "}\n",
    "\n",
    "for run_name, paths in run_pairs.items():\n",
    "    base_path = os.path.join(inmap_run_dir, paths['base'])\n",
    "    sens_path = os.path.join(inmap_run_dir, paths['sens'])\n",
    "\n",
    "    # Load the shapefiles\n",
    "    gdf1 = load_shapefile(base_path)\n",
    "    gdf2 = load_shapefile(sens_path)\n",
    "\n",
    "    # Initialize a new GeoDataFrame for the differences\n",
    "    gdf_diff = gdf1[['geometry']].copy()  # Copy only the geometry column\n",
    "\n",
    "    columns = gdf1.columns.difference(['geometry', 'FIPS'])\n",
    "\n",
    "    # Compute the differences and add them as new fields to gdf_diff\n",
    "    for field in columns:\n",
    "        gdf_diff[field] = gdf2[field] - gdf1[field]\n",
    "        gdf_diff[field+'_base'] = gdf1[field]  # save base run results\n",
    "    #gdf_diff.to_file(output_dir + 'National_LA_CSS_impact_diff_output.shp')\n",
    "\n",
    "    # create a directory for each run pair\n",
    "    run_output_dir = os.path.join(analysis_output_dir, run_name)\n",
    "    if not os.path.exists(run_output_dir):\n",
    "        os.makedirs(run_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "import contextily as ctx\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Add the path to the main package directory\n",
    "package_path = os.path.abspath('/Users/yunhalee/Documents/LOCAETA/LOCAETA_AQ/LOCAETA_AQ')\n",
    "if package_path not in sys.path:\n",
    "    sys.path.append(package_path)\n",
    "\n",
    "import inmap_analysis\n",
    "\n",
    "inmap_run_dir = '/Users/yunhalee/Documents/LOCAETA/RCM/INMAP/inmap-1.9.6-gridsplit/outputs/'\n",
    "output_dir = '/Users/yunhalee/Documents/LOCAETA/LOCAETA_AQ/outputs/model_analysis/'\n",
    "webdata_path = '/Users/yunhalee/Documents/LOCAETA/github/LOCAETA/WebTool/Data/'\n",
    "\n",
    "# Define pairs of base and sensitivity runs\n",
    "run_pairs = {\n",
    "    #  'CO_CCS': {\n",
    "    #      'base': 'base_nei2020/2020nei_output_run_steady.shp',\n",
    "    #      'sens': 'CO_CCS/2020nei_output_run_steady.shp'\n",
    "    #  },\n",
    "    # 'CO_CCS_wo_NH3_VOC': {\n",
    "    #     'base': 'base_nei2020/2020nei_output_run_steady.shp',\n",
    "    #     'sens': 'CO_CCS_wo_NH3_VOC/2020nei_output_run_steady.shp'\n",
    "    # },\n",
    "    # 'CO_Suncor_CCS_wo_NH3_VOC': {\n",
    "    #     'base': 'base_nei2020/2020nei_output_run_steady.shp',\n",
    "    #     'sens': 'CO_Suncor_CCS_wo_NH3_VOC/2020nei_output_run_steady.shp'\n",
    "    # },\n",
    "    # 'CO_Cherokee_CCS_wo_NH3_VOC': {\n",
    "    #     'base': 'base_nei2020/2020nei_output_run_steady.shp',\n",
    "    #     'sens': 'CO_Cherokee_CCS_wo_NH3_VOC/2020nei_output_run_steady.shp'\n",
    "    # }\n",
    "    # 'NEI_no_Landfill_2001411':{\n",
    "    #     'base': 'base_nei2020/2020nei_output_run_steady.shp',\n",
    "    #     'sens': 'NEI_no_Landfill_2001411/2020nei_output_run_steady.shp'\n",
    "    # }\n",
    "    'TN_DataCenter_NOx_2ppm': {\n",
    "        'base': 'base_nei2020/2020nei_output_run_steady.shp',\n",
    "        'sens': 'data_center_NOx_2ppm/2020nei_output_run_steady.shp'\n",
    "    },\n",
    "    'TN_DataCenter_NOx_25ppm': {\n",
    "        'base': 'base_nei2020/2020nei_output_run_steady.shp',\n",
    "        'sens': 'data_center_NOx_25ppm/2020nei_output_run_steady.shp'\n",
    "    }\n",
    "\n",
    "}\n",
    "\n",
    "inmap_to_geojson = ['TotalPM25']\n",
    "\n",
    "state_regions = {'TN':['47'] } #  state_regions = {\"CO\": '08'}\n",
    "\n",
    "for run_name, paths in run_pairs.items():\n",
    "    gdf_diff = inmap_analysis.process_run_pair(run_name, paths, inmap_run_dir)\n",
    "\n",
    "    # create a directory for each run pair\n",
    "    run_output_dir = os.path.join(output_dir, run_name)\n",
    "    if not os.path.exists(run_output_dir):\n",
    "        os.makedirs(run_output_dir)\n",
    "\n",
    "    # compare the changes of PopD matches PM25.\n",
    "    #inmap_analysis.compare_pm25_mortality_changes(gdf_diff,run_output_dir, run_name)\n",
    "    min_pop_idx = gdf_diff['TotalPopD'].idxmin()\n",
    "    gdf_diff = gdf_diff.drop(index=min_pop_idx)\n",
    "    \n",
    "    for v in inmap_to_geojson:\n",
    "        #inmap_analysis.create_interactive_map(gdf_diff, v, run_output_dir)\n",
    "\n",
    "        ## This plot must only for the state (otherwise it takes very long to plot the map)\n",
    "        # note - subset gdf_diff for the state of your interest (unforunately, INMAP doesn't carry FIPS)\n",
    "        for state, state_fips in state_regions.items():\n",
    "            print(f\"subsetting the dataset for the state {state_fips}\")\n",
    "            gdf_subset = inmap_analysis.subset_state(gdf_diff, state_fips)\n",
    "            print(gdf_subset.shape)\n",
    "            inmap_analysis.plot_spatial_distribution_percent_change_with_basemap(gdf_subset, v, run_output_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read county polygon information from this shapefile (needed for non-point sources)\n",
    "shapefile_path = \"/Users/yunhalee/Documents/LOCAETA/NEI_emissions/NEI_2020_gaftp_Jun2024/emiss_shp2020/Census/cb_2020_us_county_500k.shp\"\n",
    "gdf_fips = gpd.read_file(shapefile_path)\n",
    "print(f\"unique FIPS are {gdf_fips['STATEFP'].unique()}\")\n",
    "gdf_diff = gdf_diff.to_crs(epsg=3857)\n",
    "gdf_fips = gdf_fips.to_crs(epsg=3857)\n",
    "\n",
    "# Get all county geometries for the state and merge them into a single geometry\n",
    "state_geom = gdf_fips[gdf_fips['STATEFP'] == state_fips].geometry.unary_union\n",
    "\n",
    "print(state_geom)\n",
    "\n",
    "# Subset your dataset using spatial intersection\n",
    "gdf_co = gdf_diff[gdf_diff.intersects(state_geom)]\n",
    "\n",
    "# check new dataset\n",
    "print(gdf_co.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_state = gpd.sjoin(gdf_diff, gdf_fips[gdf_fips[\"STATEFP\"] == \"08\"], how=\"inner\", predicate=\"intersects\")\n",
    "print(f\"Subset contains {len(gdf_state)} records.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import folium\n",
    "from folium import LayerControl\n",
    "import branca.colormap as cm\n",
    "\n",
    "def create_interactive_map(gdf_diff, field, output_dir):\n",
    "    # Ensure the GeoDataFrame has a valid CRS\n",
    "    if gdf_diff.crs is None:\n",
    "        gdf_diff.set_crs(epsg=4326, inplace=True)\n",
    "    else:\n",
    "        gdf_diff.to_crs(epsg=4326, inplace=True)\n",
    "\n",
    "    # Create an index column for referencing in the choropleth map\n",
    "    # gdf_diff = gdf_diff.reset_index()\n",
    "\n",
    "    # Create a custom colormap\n",
    "    min_value = gdf_diff[field].min()\n",
    "    max_value = gdf_diff[field].max()\n",
    "\n",
    "    colormap = cm.LinearColormap(\n",
    "        colors=['blue', 'white', 'red'],\n",
    "        vmin=-2, #min_value, #-2, #0.5,\n",
    "        vmax=2, #max_value, #2, #0.5,\n",
    "        caption=f'{field} Difference'\n",
    "    )\n",
    "\n",
    "    # Create a base map centered around the centroid of the GeoDataFrame\n",
    "    map_center = [gdf_diff.geometry.centroid.y.mean(), gdf_diff.geometry.centroid.x.mean()]\n",
    "    m = folium.Map(location=map_center, zoom_start=6)\n",
    "\n",
    "    # Add the GeoDataFrame to the map with the custom colormap\n",
    "    folium.GeoJson(\n",
    "        gdf_diff,\n",
    "        name=field,\n",
    "        style_function=lambda x: {\n",
    "            'fillColor': colormap(x['properties'][field]),\n",
    "            'color': 'black',\n",
    "            'weight': 0.5,\n",
    "            'fillOpacity': 0.7,\n",
    "        },\n",
    "        tooltip=folium.features.GeoJsonTooltip(\n",
    "            fields=[field],\n",
    "            aliases=[f'{field} Difference:'],\n",
    "            localize=True\n",
    "        )\n",
    "    ).add_to(m)\n",
    "\n",
    "    # Add the colormap to the map\n",
    "    colormap.add_to(m)\n",
    "\n",
    "    # Add layer control to toggle different layers\n",
    "    LayerControl().add_to(m)\n",
    "\n",
    "    # Find the location of the maximum value\n",
    "    max_idx = gdf_diff[field].idxmax()\n",
    "    max_location = gdf_diff.loc[max_idx, 'geometry'].centroid\n",
    "\n",
    "    # Add a circle marker at the location with the maximum value\n",
    "    folium.CircleMarker(\n",
    "        location=[max_location.y, max_location.x],\n",
    "        radius=10,  # Adjust the radius as needed\n",
    "        color='red',\n",
    "        fill=True,\n",
    "        fill_color='red',\n",
    "        fill_opacity=0.6,\n",
    "        popup=f'Max {field}: {max_value}'\n",
    "    ).add_to(m)\n",
    "\n",
    "    # Find the location of the minimum value\n",
    "    min_idx = gdf_diff[field].idxmin()\n",
    "    min_location = gdf_diff.loc[min_idx, 'geometry'].centroid\n",
    "\n",
    "    # Add a circle marker at the location with the minimum value\n",
    "    folium.CircleMarker(\n",
    "        location=[min_location.y, min_location.x],\n",
    "        radius=10,  # Adjust the radius as needed\n",
    "        color='blue',\n",
    "        fill=True,\n",
    "        fill_color='blue',\n",
    "        fill_opacity=0.6,\n",
    "        popup=f'Min {field}: {min_value}'\n",
    "    ).add_to(m)\n",
    "\n",
    "    # Save the map to an HTML file\n",
    "    m.save(f\"{output_dir}Only_LA_CSS_{field}_interactive_map.html\")\n",
    "\n",
    "    # Display the map in Jupyter Notebook (if using Jupyter)\n",
    "    return m\n",
    "\n",
    "field = 'TotalPopD' \n",
    "output_dir = '/Users/yunhalee/Documents/LOCAETA/RCM/model_eval/'\n",
    "create_interactive_map(gdf_diff, field, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is for SR matrix\n",
    "\n",
    "# Compute column sums\n",
    "col_sums_list = ['deathsK','deathsL']\n",
    "column_sums = gdf_diff[col_sums_list].sum()\n",
    "print(\"Column Sums:\\n\", column_sums)\n",
    "\n",
    "\n",
    "# Compute area-weighted averages\n",
    "gdf_diff['area'] = gdf_diff.geometry.area\n",
    "area_weighted_averages = {}\n",
    "\n",
    "print(gdf_diff.columns)\n",
    "area_weight_list =['pNH4','pNO3','pSO4','PrimPM25','TotalPM25' ]\n",
    "for field in area_weight_list:\n",
    "    area_weighted_averages[field] = (gdf_diff[field] * gdf_diff['area']).sum() / gdf_diff['area'].sum()\n",
    "\n",
    "print(\"Area-Weighted Averages:\")\n",
    "for key, value in area_weighted_averages.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ATTENTION ### \n",
    "# I am going to remove the row with the minimum TotalPopD, which doesn't look right. \n",
    "min_pop_idx = gdf_diff['TotalPopD'].idxmin()\n",
    "gdf_diff = gdf_diff.drop(index=min_pop_idx)\n",
    "\n",
    "\n",
    "# Compute column sums\n",
    "col_sums_list = ['AsianD', 'BlackD', 'LatinoD', 'NativeD','WhitNoLatD', 'TotalPopD']\n",
    "column_sums = gdf_diff[col_sums_list].sum()\n",
    "print(\"Column Sums:\\n\", column_sums)\n",
    "\n",
    "# Compute area-weighted averages\n",
    "gdf_diff['area'] = gdf_diff.geometry.area\n",
    "area_weighted_averages = {}\n",
    "\n",
    "area_weight_list =['NH3','NOx','SOA','SOx', 'PNH4','PNO3','PSO4','PrimPM25','TotalPM25' ]\n",
    "for field in area_weight_list:\n",
    "    area_weighted_averages[field] = (gdf_diff[field] * gdf_diff['area']).sum() / gdf_diff['area'].sum()\n",
    "\n",
    "print(\"Area-Weighted Averages:\")\n",
    "for key, value in area_weighted_averages.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot area_weighted_AQ changes from all run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "main_dir = '/Users/yunhalee/Documents/LOCAETA/LOCAETA_AQ/outputs/model_analysis/'\n",
    "run_list = [ 'TN_DataCenter_NOx_2ppm','TN_DataCenter_NOx_25ppm'] # ['CO_CCS', 'CO_CCS_wo_NH3_VOC', 'CO_Suncor_CCS_wo_NH3_VOC','CO_Cherokee_CCS_wo_NH3_VOC', 'NEI_no_Landfill_2001411'] # ['LA_CCS', 'LA_CCS_noNH3'] # \n",
    "target_file = 'area_weighted_averages.csv'\n",
    "final_output = 'area_weighted_averages_all_runs.png'\n",
    " \n",
    "combined_df = None\n",
    "\n",
    "for run in run_list:\n",
    "    output_path = os.path.join(main_dir, run)\n",
    "    df = pd.read_csv(output_path + '/'+target_file)\n",
    "\n",
    "    df.rename(columns={\"Area-Weighted Average\": run}, inplace=True)\n",
    "\n",
    "    # Merge on 'Species' column\n",
    "    if combined_df is None:\n",
    "        combined_df = df  # First dataframe, set as base\n",
    "    else:\n",
    "        combined_df = pd.merge(combined_df, df, on=\"Species\", how=\"outer\")\n",
    "\n",
    "# Print and check final DataFrame\n",
    "print(combined_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "# Define your desired order of species\n",
    "species_order = [\"NH3\", \"SOA\", \"NOx\",\"SOx\",\"PNH4\", \"PNO3\", \"PSO4\", \"PrimPM25\", \"TotalPM25\"]  # Modify as needed\n",
    "\n",
    "# Convert DataFrame from wide to long format\n",
    "df_long = combined_df.melt(id_vars=[\"Species\"], var_name=\"Run\", value_name=\"Area-Weighted Average\")\n",
    "\n",
    "# Convert \"Species\" to a categorical type with the defined order\n",
    "species_cat = CategoricalDtype(categories=species_order, ordered=True)\n",
    "df_long[\"Species\"] = df_long[\"Species\"].astype(species_cat)\n",
    "\n",
    "# Sort the DataFrame to ensure correct plotting order\n",
    "df_long = df_long.sort_values(\"Species\")\n",
    "\n",
    "\n",
    "# Set Seaborn style\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Create figure and bar plot\n",
    "plt.figure(figsize=(14, 8))\n",
    "ax = sns.barplot(data=df_long, x=\"Species\", y=\"Area-Weighted Average\", hue=\"Run\", palette=\"tab10\")\n",
    "\n",
    "# Customize the plot\n",
    "plt.title(\"Area-Weighted Averages by Species Across Runs\", fontsize=25, fontweight=\"bold\", pad=20)\n",
    "plt.xlabel(\"Species\", fontsize=20)\n",
    "plt.ylabel(\"Area-Weighted Average [ug/mÂ³]\", fontsize=18)\n",
    "plt.xticks(rotation=45, fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "plt.legend(title=\"Run\", title_fontsize=14, fontsize=16, frameon=True)\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "# Add subtle vertical gridlines between categories\n",
    "for i in range(len(ax.get_xticks())):\n",
    "    ax.axvline(x=i - 0.5, color='grey', linestyle='--', linewidth=0.5, alpha=0.3)\n",
    "\n",
    "# Show plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(main_dir+run_list[0]+\"/\"+final_output, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from great_tables import GT\n",
    "\n",
    "def format_if_not_zero(val, format_string):\n",
    "    \"\"\"Formats the value if it's not zero, otherwise returns the original value.\"\"\"\n",
    "    return format_string.format(val) if val != 0 else val\n",
    "\n",
    "format_string = \"{:.6f}\"\n",
    "\n",
    "# Apply the formatting\n",
    "for col in combined_df.columns:\n",
    "    \n",
    "    if combined_df[col].dtype == 'float64':\n",
    "        combined_df[col] = combined_df[col].apply(lambda x: format_if_not_zero(x, format_string))\n",
    "\n",
    "combined_df.to_csv(main_dir+run_list[0]+\"/\"+\"area_weighted_avg_for_all_runs.csv\", index=False)\n",
    "GT(combined_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
