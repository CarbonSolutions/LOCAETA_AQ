{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare INMAP and BenMAP mortality output\n",
    "\n",
    "Author : Yunha Lee \n",
    "\n",
    "Date: Mar 26, 2025\n",
    "\n",
    "INMAP mortality is based on Krewski et al. (2009).\n",
    " - using a Cox proportional hazards model and assuming a 6% increase in overall mortality for every 10 μg/m³ increase in PM2.5 concentration \n",
    " - for the adults aged 30 and older  (double check this)\n",
    "\n",
    "BenMAP mortality is based on Di et al. (2017)\n",
    " - causal inference methods (e.g., doubly robust approaches, machine learning techniques) and a log-linear exposure-response function.\n",
    " - aged 65 and older\n",
    " - The estimated risk is higher than Krewski et al. (2009)\n",
    " - adverse effects even at low PM₂.₅ concentrations\n",
    "\n",
    "\n",
    "**Important note:** The comparisons will be done for total health impact, not by regions because different grid resolutions.  INMAP output is varying grids, while BenMAP output is at county-level (can be coarser than INMAP).\n",
    "\n",
    "Next step : I plan to include BenMAP with Pope et al (2019), which includes younger population\n",
    "  \n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Read INMAP mortality sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "main_dir = '/Users/yunhalee/Documents/LOCAETA/LOCAETA_AQ/outputs/model_analysis/'\n",
    "run_list = ['LA_CCS', 'LA_CCS_noNH3'] # ['CO_CCS', 'CO_CCS_wo_NH3_VOC', 'CO_Suncor_CCS_wo_NH3_VOC','CO_Cherokee_CCS_wo_NH3_VOC', 'NEI_no_Landfill_2001411']\n",
    "target_file = 'mortality_sums.csv'\n",
    "\n",
    "combined_df = None\n",
    "\n",
    "for run in run_list:\n",
    "    output_path = os.path.join(main_dir, run)\n",
    "    df = pd.read_csv(output_path + '/'+target_file, header=None)\n",
    "\n",
    "    df.columns = [\"Race\", \"INMAP_Krewski: \"+run]\n",
    "\n",
    "    # Merge on 'Species' column\n",
    "    if combined_df is None:\n",
    "        combined_df = df  # First dataframe, set as base\n",
    "    else:\n",
    "        combined_df = pd.merge(combined_df, df, on=\"Race\", how=\"outer\")\n",
    "\n",
    "combined_df.dropna(inplace=True)\n",
    "print(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_inmap ={'TotalPopD': 'ALL', 'AsianD': 'ASIAN','BlackD':'BLACK', 'NativeD':\"NATAMER\", 'LatinoD': \"HISPANIC\",'WhitNoLatD':'WHITE'}\n",
    "\n",
    "# change INMAP race value to match BenMAP\n",
    "combined_df['Race'] = combined_df['Race'].replace(rename_inmap)\n",
    "\n",
    "# Change the sign of value to match BenMAP\n",
    "for name in combined_df.columns:\n",
    "    if name != 'Race': \n",
    "        combined_df[name] = combined_df[name] * -1 # convert negative value to positive \n",
    "\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Read BenMAP mortality sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benmap_file = '/Users/yunhalee/Documents/LOCAETA/LOCAETA_AQ/outputs/BenMAP/county/incidence_results/Health_Benefit_all_CO_runs.csv'\n",
    "\n",
    "df_benmap = pd.read_csv(benmap_file)\n",
    "\n",
    "df_benmap['Endpoint'] = df_benmap['Endpoint'].str.strip()\n",
    "\n",
    "print(df_benmap['Endpoint'])\n",
    "\n",
    "# delete the first column and Endpoint, which is just row number\n",
    "df_benmap = df_benmap.drop(df_benmap.columns[0], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "def subset_clean_benmap_df(df, author_name):\n",
    "    # subset mortality using author \n",
    "    df = df[df['Endpoint'].str.contains(author_name, na=False)]\n",
    "\n",
    "    # delete the Endpoint column\n",
    "    df = df.drop(df.columns[0], axis=1)\n",
    "\n",
    "    # rename columns to contain benmap\n",
    "    for name in df.columns:\n",
    "        if name != 'Race': \n",
    "            df.rename(columns={name: f\"BenMAP_{author_name}: \" + name}, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "df_benmap_Di = subset_clean_benmap_df(df_benmap, 'Di')\n",
    "df_benmap_Pope = subset_clean_benmap_df(df_benmap, 'Pope')\n",
    "\n",
    "merged_benmap_df = pd.merge(df_benmap_Di, df_benmap_Pope, on='Race', how='inner')\n",
    "print(merged_benmap_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# combine two dataframe\n",
    "merged_df = combined_df.merge(merged_benmap_df, on=\"Race\", how=\"inner\")\n",
    "\n",
    "# Set seaborn style\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Convert the column to categorical with the specified order\n",
    "race_order = [\"ALL\",\"WHITE\",  \"BLACK\", \"ASIAN\", \"NATAMER\", \"HISPANIC\"]\n",
    "merged_df['Race'] = pd.Categorical(merged_df['Race'], categories=race_order, ordered=True)\n",
    "\n",
    "# Sort the DataFrame by the ordered Race column\n",
    "merged_df = merged_df.sort_values(by='Race')\n",
    "\n",
    "# Ensure \"Race\" is the index\n",
    "merged_df.set_index(\"Race\", inplace=True)\n",
    "\n",
    "\n",
    "# Extract unique run names, excluding \"Race\"\n",
    "run_names = set(col.split(\": \")[1] for col in merged_df.columns if \": \" in col)\n",
    "\n",
    "print(run_names)\n",
    "\n",
    "# Plot comparison for each run\n",
    "for run in run_names:\n",
    "    inmap_col = f\"INMAP_Krewski: {run}\"\n",
    "    benmap_col = f\"BenMAP_Di: {run}\"\n",
    "    benmap_col2 = f\"BenMAP_Pope: {run}\"\n",
    "    \n",
    "    if inmap_col in merged_df.columns and benmap_col in merged_df.columns:\n",
    "        # Create a new DataFrame for plotting\n",
    "        plot_df = merged_df[[inmap_col, benmap_col, benmap_col2]]\n",
    "\n",
    "        print(\"checking subset\", plot_df)\n",
    "\n",
    "        # Plot\n",
    "        ax = plot_df.plot(kind=\"bar\", figsize=(8, 5), width=0.7, color=[\"Blue\", \"Red\", \"Green\"], alpha = 0.6)  # Blue & Orange for better contrast\n",
    "        plt.title(f\"Comparison of {run} between INMAP and BenMAP\", fontsize=14)\n",
    "        plt.xlabel(\"Race\", fontsize=12)\n",
    "        plt.ylabel(\"Annual avoided number of death\", fontsize=12)\n",
    "        plt.xticks(rotation=45, fontsize=10)\n",
    "        plt.yticks(fontsize=10)\n",
    "        plt.legend([\"INMAP:Kreswki et al.\", \"BenMAP:Di et al.\", \"BenMAP:Pope et al.\"], fontsize=12)\n",
    "        #plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "        ax.grid(False)  # Completely removes the grid\n",
    "        \n",
    "        # Add subtle vertical gridlines between categories\n",
    "        for i in range(len(ax.get_xticks())):\n",
    "            ax.axvline(x=i - 0.5, color='grey', linestyle='--', linewidth=0.5, alpha=0.3)\n",
    "\n",
    "        # Add value labels on top of bars\n",
    "        for p in ax.patches:\n",
    "            ax.annotate(f'{p.get_height():.1f}',  \n",
    "                        (p.get_x() + p.get_width() / 2., p.get_height()),  \n",
    "                        ha='center', va='bottom', fontsize=9, fontweight='bold', color='black')\n",
    "\n",
    "        plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
