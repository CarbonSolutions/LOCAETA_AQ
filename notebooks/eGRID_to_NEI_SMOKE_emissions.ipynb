{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Preparing NEI-SMOKE format emissions using eGRID-based output\n",
    "\n",
    "This is the emission processing for the second \"prong\" of LOCAETA's three decarbonization strategies, electrification. The goal of the study is assessing the impact of changes of energy demands given a grid scenario (e.g., current and 2050 grid). For example, what will be the emissions increases at power plants in the region of the facility(ies)? We explored the hypothetical scenario which essentially assumes that each power plant in the region (region defined by NRELâ€™s Cambium model) marginally increases its output to collectively meet an additional 300MW load that would be incurred if the data center were connected to the grid.\n",
    "\n",
    "About the emissions generated from eGRID, it is computed for each powerplant facility (EIS ID is a unique identifier). To include these emissions into NEI-SMOKE formated emissions, I need to split the emisisons using 2020 NEI emissions (per EIS ID and per SCC). \n",
    "\n",
    "Here is the emissions scenarios considered and the stretegy I use to prepare NEI-SMOKE style emissions for each scenario: \n",
    "\n",
    "* current_2020  - emissions can be prepared by splitting into each SCC by the NEI 2020 emissions weight\n",
    "* decarb95_2050 - can be prepared by splitting into each SCC by the NEI 2020 emissions weight\n",
    "* highREcost_2050 -  can be prepared by splitting into each SCC by the NEI 2020 emissions weight\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Step 1: Read eGRID emissions and NEI-SMOKE all point source shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os\n",
    "\n",
    "def reformat_egrid(egrid):\n",
    "    # columns I need\n",
    "    pollutant_cols = [col for col in egrid.columns if '_tons_final' in col]\n",
    "    base_cols = [col for col in egrid.columns if '_tons_base' in col]\n",
    "    egrid_col_names = pollutant_cols + base_cols + ['ghgrp_facility_id', 'oris', 'eis']\n",
    "\n",
    "    # subset the dataframe \n",
    "    egrid = egrid[egrid_col_names] \n",
    "\n",
    "    # remove rows if ghgrp_facility_id is NaN, which is the case for renewable energy rows\n",
    "    egrid = egrid.dropna(subset=['ghgrp_facility_id'])\n",
    "\n",
    "    # Define columns as integers\n",
    "    egrid = egrid.astype({'ghgrp_facility_id': 'int64', 'oris': 'int64', 'eis': 'int64'})\n",
    "\n",
    "    # rename \"eis\" to \"eis_id\"\n",
    "    egrid.rename(columns={'eis': 'EIS_ID', 'oris':'oris_id'}, inplace=True)\n",
    "\n",
    "    print(egrid.head())\n",
    "\n",
    "    return egrid\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "def find_minimal_unique_identifier_columns(df, max_combination_size=30):\n",
    "    \"\"\"\n",
    "    Finds the minimal set of columns that uniquely identify rows in a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df: pandas.DataFrame\n",
    "        max_combination_size: int, maximum number of columns to consider in combinations (avoid long runtime)\n",
    "\n",
    "    Returns:\n",
    "        List of column names or None\n",
    "    \"\"\"\n",
    "    cols = df.columns.tolist()\n",
    "    for r in range(1, min(len(cols), max_combination_size) + 1):\n",
    "        for combo in combinations(cols, r):\n",
    "            if not df.duplicated(subset=combo).any():\n",
    "                return list(combo)\n",
    "    return None\n",
    "\n",
    "def mapping_egrid_to_nei(nei_with_egrid, nei_all_pt, unique_identifier_columns, is_base):\n",
    "\n",
    "    if is_base: \n",
    "        # Column mapping between NEI and eGRID\n",
    "        pollutant_map = {\n",
    "            'NOx': 'NOx_tons_base',\n",
    "            'PM2_5': 'PM2.5_tons_base',\n",
    "            'VOC': 'VOC_tons_base',\n",
    "            'NH3': 'NH3_tons_base',\n",
    "            'SOx': 'SO2_tons_base'\n",
    "        }\n",
    "    else:\n",
    "        pollutant_map = {\n",
    "            'NOx': 'NOx_tons_final',\n",
    "            'PM2_5': 'PM2.5_tons_final',\n",
    "            'VOC': 'VOC_tons_final',\n",
    "            'NH3': 'NH3_tons_final',\n",
    "            'SOx': 'SO2_tons_final'\n",
    "        }\n",
    "\n",
    "    #print(\"before\", nei_with_egrid.head())\n",
    "    # Compute and apply split factors per pollutant\n",
    "    for nei_col, egrid_col in pollutant_map.items():\n",
    "\n",
    "        print (nei_col, egrid_col)\n",
    "        # Group sum for each pollutant by EIS_ID\n",
    "        total_by_eis = nei_with_egrid.groupby('EIS_ID')[f'{nei_col}_nei'].transform('sum')\n",
    "        nei_with_egrid[f'{nei_col}_total_by_eis'] = total_by_eis\n",
    "\n",
    "        # Default: compute split factor using NEI emissions\n",
    "        split_col = f'{nei_col}_split'\n",
    "        nei_with_egrid[split_col] = nei_with_egrid[f'{nei_col}_nei'] / total_by_eis.replace(0, pd.NA)\n",
    "\n",
    "        # Find EIS_IDs where total_by_eis is zero but eGRID_col is non-zero\n",
    "        mask_zero_total = (total_by_eis == 0) & nei_with_egrid[egrid_col].notna() & (nei_with_egrid[egrid_col] != 0)\n",
    "\n",
    "        # For these EIS_IDs, assign equal split factor across matching rows\n",
    "        for eid in nei_with_egrid.loc[mask_zero_total, 'EIS_ID'].unique():\n",
    "            match_rows = nei_with_egrid['EIS_ID'] == eid\n",
    "            n_rows = match_rows.sum()\n",
    "            nei_with_egrid.loc[match_rows, split_col] = 1.0 / n_rows\n",
    "\n",
    "        # Now compute eGRID-scaled emissions and save as nei original name\n",
    "        nei_with_egrid[f'{nei_col}'] = nei_with_egrid[split_col] * nei_with_egrid[egrid_col]\n",
    "\n",
    "    # OPTIONAL: Drop intermediate split columns\n",
    "    #nei_with_egrid.drop(columns=[f'{k}_split' for k in pollutant_map], inplace=True)\n",
    "    # Merge results back into the full NEI dataset\n",
    "\n",
    "    # Merge results back into the full NEI dataset\n",
    "    nei_all_pt_final = nei_all_pt.merge(\n",
    "        nei_with_egrid[\n",
    "            unique_identifier_columns + [f'{k}' for k in pollutant_map]\n",
    "        ],\n",
    "        on=unique_identifier_columns,\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    for k in pollutant_map:\n",
    "        nei_all_pt_final[f'{k}'] = nei_all_pt_final[f'{k}'].fillna(nei_all_pt_final[f'{k}_nei'])\n",
    "\n",
    "\n",
    "    return nei_all_pt_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import os\n",
    "\n",
    "egrid_dir_path = '/Users/yunhalee/Documents/LOCAETA/eGRID_emissions/'\n",
    "nei_pt_emis_file_path = '/Users/yunhalee/Documents/LOCAETA/RCM/INMAP/evaldata_v1.6.1/2020_nei_emissions/combined_NEI2020_pt_oilgas_ptegu_ptnonipm.shp'\n",
    "\n",
    "# read base and sens emission scenarios\n",
    "nei_all_pt = gpd.read_file(nei_pt_emis_file_path) \n",
    "\n",
    "# Reset index to ensure proper comparison\n",
    "nei_all_pt.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(nei_all_pt.head())\n",
    "\n",
    "# rename the nei emissions\n",
    "pollutant_cols = ['NOx','PM2_5', 'VOC','NH3', 'SOx']\n",
    "\n",
    "col_dict = {}\n",
    "for poll in pollutant_cols:\n",
    "    col_dict[poll] = f'{poll}_nei'\n",
    "\n",
    "nei_all_pt.rename(columns = col_dict, inplace=True)\n",
    "\n",
    "# remove duplicates\n",
    "print(nei_all_pt[nei_all_pt.duplicated()])\n",
    "nei_all_pt = nei_all_pt[~nei_all_pt.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "egrids_list = [\"highREcost_2050\", \"decarb95_2050\", \"current_2020\"] \n",
    "is_base_emission = True\n",
    "\n",
    "for egrid_name in egrids_list:\n",
    "\n",
    "    print (\"processing \", egrid_name)\n",
    "    egrid_file = os.path.join(egrid_dir_path, f'ProjectX_{egrid_name}.csv')\n",
    "    egrid = pd.read_csv(egrid_file) \n",
    "\n",
    "    egrid = reformat_egrid(egrid)\n",
    "\n",
    "    # Filter NEI rows to only those that exist in eGRID\n",
    "    nei_with_egrid = nei_all_pt[nei_all_pt['EIS_ID'].isin(egrid['EIS_ID'])].copy()\n",
    "\n",
    "    # Subset only for necessary columns\n",
    "    nei_with_egrid.drop(columns=['height', 'diam',\n",
    "        'temp', 'velocity'], inplace=True)\n",
    "\n",
    "    unique_identifier_columns = find_minimal_unique_identifier_columns(nei_with_egrid)\n",
    "\n",
    "    if unique_identifier_columns:\n",
    "        print(\"Columns that uniquely identify rows:\", unique_identifier_columns)\n",
    "    else:\n",
    "        print(\"No combination of columns uniquely identifies rows.\")\n",
    "\n",
    "    print(\"filtering\", nei_with_egrid.shape)\n",
    "\n",
    "    # Merge eGRID emissions\n",
    "    nei_with_egrid = nei_with_egrid.merge(egrid, on='EIS_ID', how='left')\n",
    "\n",
    "    print(\"Merging egrid\", nei_with_egrid.shape)\n",
    "\n",
    "    nei_all_pt_final = mapping_egrid_to_nei(nei_with_egrid, nei_all_pt, unique_identifier_columns, is_base = is_base_emission)\n",
    "    \n",
    "    if is_base_emission:\n",
    "        # save output files\n",
    "        filepath = egrid_dir_path  + egrid_name +\"_base_debugging.csv\"\n",
    "        nei_with_egrid.to_csv(filepath)\n",
    "\n",
    "        filepath = egrid_dir_path  + egrid_name +\"_base.shp\"\n",
    "        nei_all_pt_final.to_file(filepath, driver='ESRI Shapefile')\n",
    "    else:\n",
    "        # save output files\n",
    "        filepath = egrid_dir_path  + egrid_name +\"_debugging.csv\"\n",
    "        nei_with_egrid.to_csv(filepath)\n",
    "\n",
    "        filepath = egrid_dir_path  + egrid_name +\".shp\"\n",
    "        nei_all_pt_final.to_file(filepath, driver='ESRI Shapefile')\n",
    "\n",
    "    print(nei_all_pt_final.shape, nei_all_pt.shape)\n",
    "    print(nei_all_pt_final['PM2_5'].notna().sum())\n",
    "    print(nei_with_egrid['PM2_5'].notna().sum())\n",
    "    print(nei_with_egrid['PM2.5_tons_final'].notna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "### Useful debugging script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the number of unique IDs\n",
    "ID_name = 'EIS_ID'\n",
    "org_egrid_list = egrid[ID_name].unique()\n",
    "egrid_list = nei_with_egrid[ID_name].unique()\n",
    "org_nei_list = nei_all_pt[ID_name].unique()\n",
    "nei_list = nei_all_pt_final[ID_name].unique()\n",
    "\n",
    "print(len(org_egrid_list), len(egrid_list), len(nei_list),len(org_nei_list))\n",
    "\n",
    "\n",
    "# find the rows where two columns are different\n",
    "missing_pm25_egrid = nei_with_egrid[\n",
    "    nei_with_egrid['PM2_5_egrid'].isna() & \n",
    "    nei_with_egrid['PM2.5_tons_final'].notna()\n",
    "]\n",
    "\n",
    "# filtering column based on string\n",
    "missing_pm25_egrid.filter(regex ='tons_final|total_by_eis')\n",
    "\n",
    "\n",
    "# get a certain ID facility\n",
    "print(nei_all_pt[(nei_all_pt['EIS_ID'] == 1028611)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "# Compare NEI2020 against Current grid base emissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Column mapping between NEI and eGRID\n",
    "pollutant_map = {\n",
    "    'NOx': 'NOx_tons_base',\n",
    "    'PM2_5': 'PM2.5_tons_base',\n",
    "    'VOC': 'VOC_tons_base',\n",
    "    'NH3': 'NH3_tons_base',\n",
    "    'SOx': 'SO2_tons_base'\n",
    "\n",
    "}\n",
    "\n",
    "# Compute and apply split factors per pollutant\n",
    "for nei_col, egrid_col in pollutant_map.items():\n",
    "    # Scatter plot of total_by_eis vs. eGRID\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.scatter(\n",
    "        nei_with_egrid[f'{nei_col}_total_by_eis'],\n",
    "        nei_with_egrid[egrid_col] - nei_with_egrid[f'{nei_col}_total_by_eis'],\n",
    "        alpha=0.5\n",
    "    )\n",
    "    plt.xlabel(f\"Total {nei_col} by EIS_ID in NEI\")\n",
    "    plt.ylabel(f\"{egrid_col} - '{nei_col}_total_by_eis'\")\n",
    "    plt.title(f\"{nei_col} NEI Total vs difference with eGRID base Emissions\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Evaluate new egrid emissions formatted for NEI-SMOKE style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import os\n",
    "\n",
    "\n",
    "egrid_dir_path = '/Users/yunhalee/Documents/LOCAETA/eGRID_emissions/'\n",
    "egrids_list = [\"current_2020\",\"decarb95_2050\",\"highREcost_2050\"]\n",
    "\n",
    "\n",
    "# Column mapping between NEI and eGRID\n",
    "pollutant_final_map = {\n",
    "    'NOx': 'NOx_tons_final',\n",
    "    'PM2_5': 'PM2.5_tons_final',\n",
    "    'VOC': 'VOC_tons_final',\n",
    "    'NH3': 'NH3_tons_final',\n",
    "    'SOx': 'SO2_tons_final'\n",
    "}\n",
    "\n",
    "# Column mapping between NEI and eGRID\n",
    "pollutant_base_map = {\n",
    "    'NOx': 'NOx_tons_base',\n",
    "    'PM2_5': 'PM2.5_tons_base',\n",
    "    'VOC': 'VOC_tons_base',\n",
    "    'NH3': 'NH3_tons_base',\n",
    "    'SOx': 'SO2_tons_base'\n",
    "}\n",
    "\n",
    "is_base_emission = True\n",
    "\n",
    "# nei emissions column names\n",
    "pollutant_cols = ['NOx','PM2_5', 'VOC','NH3', 'SOx']\n",
    "\n",
    "for egrid_name in egrids_list:\n",
    "\n",
    "    if is_base_emission: \n",
    "        pollutant_map = pollutant_base_map\n",
    "        file_path = os.path.join(egrid_dir_path, f'{egrid_name}_base.shp')  \n",
    "    else:\n",
    "        pollutant_map = pollutant_final_map\n",
    "        file_path = os.path.join(egrid_dir_path, f'{egrid_name}.shp')  \n",
    "\n",
    "    # read emission scenario\n",
    "    final_egrid_emis = gpd.read_file(file_path) \n",
    "\n",
    "    # Reset index to ensure proper comparison\n",
    "    final_egrid_emis.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Subset rows where actual egrid emissions are available (egrid â‰  nei for any pollutant)\n",
    "    mask = pd.concat([\n",
    "        final_egrid_emis[k] != final_egrid_emis[f'{k}_nei']\n",
    "        for k in pollutant_cols\n",
    "    ], axis=1).any(axis=1)\n",
    "\n",
    "    final_egrid_emis = final_egrid_emis[mask]\n",
    "\n",
    "    # Compute group sums for each pollutant by EIS_ID\n",
    "    group_sums = final_egrid_emis.groupby('EIS_ID')[[k for k in pollutant_cols]].sum().reset_index()\n",
    "\n",
    "    group_sums.head()\n",
    "\n",
    "    print (\"processing \", egrid_name)\n",
    "    original_egrid_file = os.path.join(egrid_dir_path, f'ProjectX_{egrid_name}.csv')\n",
    "    original_egrid = pd.read_csv(original_egrid_file) \n",
    "    original_egrid = reformat_egrid(original_egrid)\n",
    "\n",
    "\n",
    "    # Merge for comparison\n",
    "    comparison_df = group_sums.merge(original_egrid, on='EIS_ID')\n",
    "    comparison_df.head()\n",
    "\n",
    "    # Scatter plots\n",
    "    for nei, egrid in pollutant_map.items():\n",
    "        x = comparison_df[nei]\n",
    "        y = comparison_df[egrid] - comparison_df[nei]\n",
    "\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        plt.scatter(x, y, alpha=0.6, edgecolors='k')\n",
    "        plt.xlabel(f'{nei} NEI egrid')\n",
    "        plt.ylabel(f'{nei} original egrid - nei egrid')\n",
    "        plt.ylim(-1, 1)\n",
    "        plt.title(f'{nei} Comparison - {egrid_name}')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## Plot the total emissions (either final or diff_final) by Species for all egrid scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Dictionary to store total emissions\n",
    "egrid_sum = {}\n",
    "\n",
    "# Column mapping between NEI and eGRID\n",
    "pollutant_diff_map = {\n",
    "    'NOx': 'NOx_tons_dif_final',\n",
    "    'PM2_5': 'PM2.5_tons_dif_final',\n",
    "    'VOC': 'VOC_tons_dif_final',\n",
    "    'NH3': 'NH3_tons_dif_final',\n",
    "    'SOx': 'SO2_tons_dif_final'\n",
    "}\n",
    "\n",
    "# Column mapping between NEI and eGRID\n",
    "pollutant_final_map = {\n",
    "    'NOx': 'NOx_tons_final',\n",
    "    'PM2_5': 'PM2.5_tons_final',\n",
    "    'VOC': 'VOC_tons_final',\n",
    "    'NH3': 'NH3_tons_final',\n",
    "    'SOx': 'SO2_tons_final'\n",
    "}\n",
    "\n",
    "pollutant_map = pollutant_diff_map\n",
    "\n",
    "for egrid_name in egrids_list: \n",
    "    print (\"processing \", egrid_name)\n",
    "    original_egrid_file = os.path.join(egrid_dir_path, f'ProjectX_{egrid_name}.csv')\n",
    "    original_egrid = pd.read_csv(original_egrid_file) \n",
    "\n",
    "    # Store totals per pollutant\n",
    "    for nei, egrid in pollutant_map.items():\n",
    "        egrid_sum.setdefault(nei, {})[egrid_name] = original_egrid[egrid].sum()\n",
    "\n",
    "    print(egrid_sum)\n",
    "\n",
    "# Convert to DataFrame: rows = pollutant, columns = egrid cases\n",
    "emissions_df = pd.DataFrame(egrid_sum).T  # Transpose so pollutants are rows\n",
    "\n",
    "# Plotting\n",
    "ax = emissions_df.plot(kind='bar', figsize=(10, 6))\n",
    "ax.set_ylabel(\"Total Emissions\")\n",
    "ax.set_title(\"Total Difference Emissions by Pollutant and eGRID Case\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.legend(title=\"eGRID Case\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
